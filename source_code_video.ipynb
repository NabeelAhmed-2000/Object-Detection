{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d8ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                                                    # For importing OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d7b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                               # For importing matplot library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf777d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'  # This is the configuration file\n",
    "frozen_model = 'frozen_inference_graph.pb'                    # This is the pre-trained TensorFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b68370",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.dnn_DetectionModel(frozen_model,config_file)      # For loading the model and configuration file into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de4fec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classLabels = []                                              # Creating an empty List in python\n",
    "file_name = 'labels.txt'                                      # Reading the contents of 'Labels.txt'\n",
    "with open(file_name,'rt') as fpt:\n",
    "    classLabels = fpt.read().rstrip('\\n').split('\\n')         # Transferring the contents of 'Labels.txt' to 'classLabels' list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e9c1c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.dnn.Model 00000238FD595290>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.setInputSize(320,320)                                   # Input size is 320x320 as defined in the configuration file\n",
    "model.setInputScale(1.0/127.5)                                # Scaling the Grey level (0-255) of image i.e. 255/2=127.5 \n",
    "model.setInputMean((127.5,127.5,127.5))                       # Taking mean of 127.5 as input domain of MobileNet is [-1,1]\n",
    "model.setInputSwapRB(True)                                    # Automatically converts image from BGR to RGB color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b393603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Resolution: 1920x1080\n",
      "End of video or cannot fetch frame.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"original_sample_video.mp4\")           # Load the video\n",
    "\n",
    "if not cap.isOpened():                                        # Check if the video opened correctly\n",
    "    cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open video\")\n",
    "\n",
    "video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))          # Automatically detect video resolution\n",
    "video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(f\"Video Resolution: {video_width}x{video_height}\")\n",
    "\n",
    "font_scale = 2\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "# Create a normal window\n",
    "cv2.namedWindow('Object Detection Tutorial', cv2.WINDOW_NORMAL) \n",
    "\n",
    "fullscreen = True                                             # Flag to toggle fullscreen mode\n",
    "\n",
    "cv2.setWindowProperty('Object Detection Tutorial', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video or cannot fetch frame.\")\n",
    "        break                                                 # Break if the video ends or frame cannot be read\n",
    "\n",
    "    # Get the screen resolution\n",
    "    screen_width = cv2.getWindowImageRect('Object Detection Tutorial')[2]\n",
    "    screen_height = cv2.getWindowImageRect('Object Detection Tutorial')[3]\n",
    "\n",
    "    aspect_ratio = video_width / video_height                 # Calculate aspect ratio\n",
    "\n",
    "    # Scale video to fit inside the window while maintaining aspect ratio\n",
    "    if screen_width / screen_height > aspect_ratio:\n",
    "        display_height = screen_height\n",
    "        display_width = int(display_height * aspect_ratio)\n",
    "    else:\n",
    "        display_width = screen_width\n",
    "        display_height = int(display_width / aspect_ratio)\n",
    "\n",
    "    resized_frame = cv2.resize(frame, (display_width, display_height))\n",
    "\n",
    "    # Center the frame with padding if necessary\n",
    "    top_padding = (screen_height - display_height) // 2\n",
    "    left_padding = (screen_width - display_width) // 2\n",
    "\n",
    "    bordered_frame = cv2.copyMakeBorder(resized_frame, top_padding, top_padding, left_padding, left_padding, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "\n",
    "    try:\n",
    "        # Detect objects in the original frame\n",
    "        ClassIndex, confidence, bbox = model.detect(frame, confThreshold=0.55)\n",
    "        if len(ClassIndex) != 0:\n",
    "            for ClassInd, conf, boxes in zip(ClassIndex.flatten(), confidence.flatten(), bbox):\n",
    "                if ClassInd <= 90:\n",
    "                    # Adjust bounding box coordinates to account for padding\n",
    "                    adjusted_box = [\n",
    "                        int(boxes[0] * display_width / video_width) + left_padding,\n",
    "                        int(boxes[1] * display_height / video_height) + top_padding,\n",
    "                        int(boxes[2] * display_width / video_width),\n",
    "                        int(boxes[3] * display_height / video_height)\n",
    "                    ]\n",
    "                    \n",
    "                    cv2.rectangle(bordered_frame, adjusted_box, (255, 0, 0), 2)\n",
    "                    \n",
    "                    # Format the label text: \"Class Name: Confidence%\"\n",
    "                    label = f\"{classLabels[ClassInd - 1]}: {conf:.2f}\"    # Format confidence to 2 decimal places\n",
    "\n",
    "                    # Get text size to avoid cutting off text\n",
    "                    (text_width, text_height), _ = cv2.getTextSize(label, font, font_scale, 2)\n",
    "                    \n",
    "                    # Adjust text position to make sure it's inside the image\n",
    "                    x, y = adjusted_box[0] + 10, adjusted_box[1] + 40\n",
    "                    \n",
    "                    # Check if the text goes beyond the image boundaries\n",
    "                    if x + text_width > screen_width:\n",
    "                        x = screen_width - text_width - 10  # Adjust x if text overflows on the right\n",
    "                    if y + text_height > screen_height:\n",
    "                        y = screen_height - text_height - 10  # Adjust y if text overflows at the bottom\n",
    "                    \n",
    "                    # Display the label with adjusted position\n",
    "                    cv2.putText(bordered_frame, label, (x, y), font, fontScale=font_scale, color=(0, 255, 0), thickness=2)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in detection: {e}\")\n",
    "\n",
    "    cv2.imshow('Object Detection Tutorial', bordered_frame)\n",
    "\n",
    "    key = cv2.waitKey(10) & 0xFF                              # Exit when 'q' is pressed\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('f'):                                     # Toggle fullscreen mode when 'f' is pressed\n",
    "        fullscreen = not fullscreen\n",
    "        if fullscreen:\n",
    "            cv2.setWindowProperty('Object Detection Tutorial', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "        else:\n",
    "            cv2.setWindowProperty('Object Detection Tutorial', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Release the video capture and destroy all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eeb1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8593aba3-ca4c-4c38-ace6-c7b49fc1a96b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
